
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>pfigue</title>
  <meta name="author" content="pfigue">

  
  <meta name="description" content="Containers LXC Containers are a relatively new way of virtualization for Linux environments. Solaris had containers since several years ago, but in &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://pfigue.github.io/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="pfigue" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>


  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-38745757-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:pfigue.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/pfigue/">About me</a></li>
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/categories/talk">Talks</a></li>
  <li><a href="/blog/categories/note">Notes</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/01/25/using-vagrant-with-lxc-linux-containers/">Using Vagrant with LXC Linux Containers</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-01-25T15:44:00+01:00" pubdate data-updated="true">Jan 25<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>Containers</h2>

<p>LXC Containers are a relatively new way of virtualization for Linux environments. Solaris had containers since several years ago, but in Linux they appeared around 5 years ago, afaik.</p>

<p>The point of virtualizing using containers instead of virtual machines is that, both, guest and host, use the same instance of the kernel, which translates in <strong>far less time to boot and far less resources used</strong>.</p>

<p>A container is just a set of resources and processes running in a different namespace, eventually with some limitations (CPU or I/O usage, memory used, etc.).</p>

<p>Afair, there are/were 2 implementations of containers for linux: OpenVZ and LXC. Without being an expert in the area, I&rsquo;d say that LXC has much better maintenance nowadays than OpenVZ.</p>

<h2>LXC Containers in Ubuntu</h2>

<p>In Ubuntu 12.04 we can install LXC as usual with <code>sudo apt-get install lxc</code>. As root, we can list the containers we have in every state with <code>sudo lxc-list</code>.</p>

<p>Usually, <a href="https://help.ubuntu.com/lts/serverguide/lxc.html#lxcbr0">once <strong>lxc</strong> is installed, we should find a new network bridge</a>: <em>lxcbr0</em>. You can check if it is present with:</p>

<pre><code>$ ifconfig lxcbr0 2&gt; /dev/null 1&gt;&amp;2  &amp;&amp; echo 'lxc interface is present' || echo 'no lxc interface'
lxc interface is present
$
</code></pre>

<p>Before start to use containers with Vagrant, we should <a href="https://github.com/fgrehm/vagrant-lxc/wiki/Avoiding-%27sudo%27-passwords">work around a bug in sudo (Ubuntu 12.04)</a>.</p>

<p>With <code>sudo visudo</code> you can add the line:</p>

<pre><code>Defaults        !tty_tickets
</code></pre>

<p>to the sudoers file. It will solve the bug.</p>

<h2>Vagrant with the LXC provider</h2>

<p>Let&rsquo;s create a new vagrant project:</p>

<pre><code>$ mkdir vagrant-lxc
$ cd vagrant-lxc/
$ vagrant init test-lxc http://dl.dropbox.com/u/13510779/lxc-precise-amd64-2013-07-12.box
</code></pre>

<p>Where the URL is an <a href="http://dl.dropbox.com/u/13510779/lxc-precise-amd64-2013-07-12.box">Ubuntu 12.04 amd64 box <strong>for LXC</strong></a> from <a href="http://vagrantbox.es/">vagrantbox.es</a>.</p>

<p>You can use the same <a href="http://pfigue.github.io/blog/2014/01/25/my-first-steps-with-vagrant/">Vagrantfile I used in the previous article</a>, but notice that the <code>config.vm.network</code> parameter is ignored by this provider.
At the moment you can only forward port, but not bridge any interface.</p>

<p>Now you can <a href="https://github.com/fgrehm/vagrant-lxc/blob/master/README.md">install there the <strong>vagrant-lxc</strong> plugin</a> with <code>vagrant plugin install vagrant-lxc</code>.</p>

<p>Once done you should already be able to fire up that box with LXC:</p>

<pre><code>$ vagrant up --provider=lxc
[default] Warning! The LXC provider doesn't support any of the Vagrant public / private
network configurations (ex: `config.vm.network :private_network, ip: "some-ip"`).
They will be silently ignored.
</code></pre>

<p><code>vagrant ssh</code> from the same <code>vagrant-lxc/</code> directory to check it, or <code>sudo lxc-list</code> or <code>lxc-ps --lxc</code> to visualice the running containers.</p>

<h2>Advantages</h2>

<p>The time needed to boot up a Vagrant box with LXC is really much lower than using VirtualBox. This translates in faster try-error loop, faster feedback and <a href="http://pfigue.github.io/blog/2014/01/25/my-first-steps-with-vagrant/">faster development of Puppet Manifest, server configuration</a>, <a href="http://pfigue.github.io/blog/2014/01/25/my-first-steps-with-vagrant/">faster testing of packages</a>, etc.</p>

<p>References:</p>

<ul>
<li> <a href="https://help.ubuntu.com/lts/serverguide/lxc.html#lxcbr0">LXC &ndash; lxcbr0</a></li>
<li> <a href="https://github.com/fgrehm/vagrant-lxc/blob/master/README.md">README for vagrant-lxc plugin</a></li>
<li> <a href="https://github.com/fgrehm/vagrant-lxc/wiki/Avoiding-%27sudo%27-passwords">vagrant-lxc &ndash; BUG &ndash; Avoiding &lsquo;sudo&rsquo; passwords</a></li>
<li> <a href="http://pfigue.github.io/blog/2014/01/25/my-first-steps-with-vagrant/">My first steps with Vagrant</a></li>
<li> <a href="http://fabiorehm.com/blog/2013/04/28/lxc-provider-for-vagrant/">LXC provider for Vagrant</a></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/01/25/my-first-steps-with-vagrant/">My first steps with Vagrant</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-01-25T12:52:00+01:00" pubdate data-updated="true">Jan 25<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>Why Vagrant?</h2>

<p>Lately I was developing my-own-solution &trade; for package deployment and now I&rsquo;d to check if I can install system packages without problems.</p>

<p><strong>Vagrant is a tool that lets me create, destroy and recreate Virtual Machines very easily</strong>, so I can in less than 5 minutes, create a new VM with a fresh install of Ubuntu 12.04 and install there the package I want to test.</p>

<p>It can also be useful to test system configuration (e.g. Puppet manifests or Chef recipes, nginx config., etc.) without playing with the production environment.</p>

<p>Another interesting use (and the reason I want to add Vagrant to the development toolchain my team uses at work) is to provide every developer with the option of packing his/her branch and deploy it with the help of Vagrant into a fresh VM, locally on his/her laptop.</p>

<p>Once deployed there, unit and functional test could be run in/against that VM, to be sure that every single branch sent to staging passed a minimal set of requirements.</p>

<h2>Replacing the old-Ubuntu-12.04 Vagrant install with a factory Vagrant.</h2>

<p>Long time ago I installed <strong>vagrant</strong> via <code>sudo apt-get install vagrant</code>, and since then I was getting an error whenever I tried to start a new project:</p>

<pre><code>$ vagrant init test1 http://cloud-images.ubuntu.com/vagrant/precise/current/precise-server-cloudimg-amd64-vagrant-disk1.box
/home/pablo/.rvm/rubies/ruby-2.0.0-p353/lib/ruby/site_ruby/2.0.0/rubygems/core_ext/kernel_require.rb:55:in `require': cannot load such file -- log4r (LoadError)
        from /home/pablo/.rvm/rubies/ruby-2.0.0-p353/lib/ruby/site_ruby/2.0.0/rubygems/core_ext/kernel_require.rb:55:in `require'
        from /usr/bin/vagrant:2:in `&lt;main&gt;'
</code></pre>

<p>I decided to remove the version of Vagrant shipped with Ubuntu 12.04, and install a new one from <a href="http://www.vagrantup.com/downloads.html">the debian package I could get via HashiCorp</a>:</p>

<pre><code>$ sudo apt-get remove --purge vagrant
$ wget "https://dl.bintray.com/mitchellh/vagrant/vagrant_1.4.3_x86_64.deb"
$ sudo dpkg -i vagrant_1.4.3_x86_64.deb
</code></pre>

<p>Due to the first installation of Vagrant, probably all the dependencies were already satisfied and I didn&rsquo;t have to install anything else.</p>

<h2>First project</h2>

<p>In Vagrant, you create a new directory for every project. In that directory will live a <code>Vagrantfile</code> with all the configuration of the VM(s) for that project.</p>

<pre><code>$ mkdir vagrant
$ cd vagrant/
$ vagrant init test1 http://cloud-images.ubuntu.com/vagrant/precise/current/precise-server-cloudimg-amd64-vagrant-disk1.box
A `Vagrantfile` has been placed in this directory. You are now
ready to `vagrant up` your first virtual environment! Please read
the comments in the Vagrantfile as well as documentation on
`vagrantup.com` for more information on using Vagrant.
</code></pre>

<p>If you are going to use Vagrant as a testing/deployment solution at work, you may find interesting to track the Vagrantfile via a <em>git</em> repository.</p>

<p>Let&rsquo;s edit the Vagrantfile a little bit to redirect the port 8080 on my laptop to the port 8000 in the test1 VM. The result would look like:</p>

<pre><code># Vagrantfile API/syntax version. Don't touch unless you know what you're doing!
VAGRANTFILE_API_VERSION = "2"

Vagrant.configure(VAGRANTFILE_API_VERSION) do |config|
  config.vm.box = "test1"
  config.vm.box_url = "http://cloud-images.ubuntu.com/vagrant/precise/current/precise-server-cloudimg-amd64-vagrant-disk1.box"
  config.vm.network :forwarded_port, guest: 8000, host: 8080
end
</code></pre>

<p>The URL <a href="http://cloud-images.ubuntu.com/vagrant/precise/current/precise-server-cloudimg-amd64-vagrant-disk1.box">http://cloud-images.ubuntu.com/vagrant/precise/current/precise-server-cloudimg-amd64-vagrant-disk1.box</a> is a boxed <a href="http://cloud-images.ubuntu.com/vagrant/precise/current/precise-server-cloudimg-amd64-vagrant-disk1.box">Ubuntu 12.04 amd64 (for VirtualBox)</a> that I found in <a href="http://www.vagantbox.es">vagrantbox.es</a>.</p>

<p>Once the file is edited and saved, if now I run <code>vagrant up</code>, as it is the first time I fire that VM up, it will fetch the .box file (around 400M big) and create the VM.</p>

<p>Per default, the virtualization <em>provider</em> is VirtualBox, but I&rsquo;ve seen boxes for VMWare and for Linux Containers (LXC).</p>

<h2>Testing the port redirect</h2>

<p>Typing <code>vagrant ssh</code> in the shell inside the <code>vagrant/</code> directory will establish an SSH session with the VM.</p>

<p>Once there you can type this to get netcat listening on port 8000 of the VM:</p>

<pre><code>$ nc -l 0.0.0.0 8000
</code></pre>

<p>In other terminal you can try to access the port 8080 of your computer (the host of the VM), like:</p>

<pre><code>$ curl http://127.0.0.1:8080
</code></pre>

<p>It should redirect the packets from 8080/tcp in the host to 8000/tcp in the VM, and you should be able to see the HTTP request in the terminal where netcat is running.</p>

<h2>Trying a network bridge instead of a port redirect</h2>

<p>If the VM will need to access a computer in the same network as the host (e.g. a database server), or the VM will be accessed by a computer different than the host (e.g. a <a href="http://code.google.com/p/selenium/wiki/Grid2">Selenium Grid</a>), you may find easier to install a network bridge better than redirect some ports.</p>

<p>With that purpose in mind, the Vagrantfile should be something like:</p>

<pre><code># Vagrantfile API/syntax version. Don't touch unless you know what you're doing!
VAGRANTFILE_API_VERSION = "2"

Vagrant.configure(VAGRANTFILE_API_VERSION) do |config|
  config.vm.box = "test1"
  config.vm.box_url = "http://cloud-images.ubuntu.com/vagrant/precise/current/precise-server-cloudimg-amd64-vagrant-disk1.box"
  config.vm.network :public_network
end
</code></pre>

<p>The new Vagrant configuration can be applied with <code>vagrant reload</code>. That command will stop (in a polite and slow way) and start again the VMs, asking this time the user in the command-line for which network interface will be the VM bridged to.</p>

<p>Once the VM is completelly booted, from a <code>vagrant ssh</code> session, the available interfaces can be checked:</p>

<pre><code>$ ifconfig -a | perl -ne 'print "$1\n" if m/^(\S+)/'
eth0
eth1
lo
$ ifconfig eth1 | grep inet\ addr
          inet addr:192.168.0.105  Bcast:192.168.0.255  Mask:255.255.255.0
</code></pre>

<p>So, my VM got the IP address 192.168.0.105. If I start a netcat in port 90/tcp with <code>sudo nc -l 0.0.0.0 90</code></p>

<p>Then, I should be able to connect to port 90/tcp of the VM from my laptop, with something like <code>telnet 192.168.0.105 90</code>.</p>

<p>Once you stop playing with Vagrant, you can stop the VM via <code>vagrant halt</code>.</p>

<p>References:</p>

<ul>
<li><p> <a href="http://www.jedi.be/blog/2011/03/28/using-vagrant-as-a-team/">Using Vagrant as a Team &ndash; Just Enough Developed Infrastructure</a></p></li>
<li><p> <a href="http://www.vagrantbox.es/">A list of base boxes for Vagrant</a></p></li>
<li><p> <a href="http://www.vagrantup.com/downloads.html">Vagrant Packages and Tarballs</a></p></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/12/06/configuring-dnsmasq-to-serve-my-own-domain-name-zone/">Configuring dnsmasq to serve my own domain name zone</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-12-06T17:07:00+01:00" pubdate data-updated="true">Dec 6<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>Why a name server and why dnsmasq.</h1>

<p>I have a datacenter (Acme GmbH.), with several environments (green, blue, live, staging), each environment with several servers (server1, server2, &hellip; serverX) and I want to use a domain name service to name every server on the datacenter, so every server can easily know what is the IP of server3.staging.acme, for example.</p>

<p>I may want also to create some aliases like puppet-master.acme.</p>

<p>While I could do this with BIND, it actually seems easier to me to user <em>dnsmasq</em>.</p>

<p>dnsmasq is a small DNS server easy to configure. It has also DHCP integration (and TFTP, PXE, etc.) but it is not what I am looking for.</p>

<p>As alternatives to use my own DNS server, I could choose some setup with Route 53 as user of Amazon. Digital Ocean or other providers may have their own systems.</p>

<h1>Installing</h1>

<p>In Ubuntu 12.04 it is just <code>sudo apt-get install dnsmasq</code>. It will launch the service, that you can stop via <code>/etc/init.d/dnsmasq stop</code>.</p>

<p>The configuration file is in <code>/etc/dnsmasq.conf</code>. The files in <code>/etc/dnsmasq.d/</code> can be included from dnsmasq.conf, but per default they aren&rsquo;t.</p>

<h1>Testing and finding the right configuration</h1>

<p>The <em>&mdash;no-daemon</em> option will be useful to do test in the command line:</p>

<pre><code>/usr/sbin/dnsmasq --no-daemon
</code></pre>

<p><em>&mdash;no-hosts</em> and <em>&mdash;addn-hosts=/etc/hosts.acme</em> will prevent dnsmasq to read /etc/hosts and instead load the datacenter zone configuration from <code>/etc/hosts.acme</code>:</p>

<pre><code>/usr/sbin/dnsmasq --no-daemon --no-hosts --addn-hosts=/etc/hosts.acme
</code></pre>

<p><em>&mdash;interface=eth0</em> will force dnsmasq to listen only on that interface. In my case, this will run in an AWS EC2 Instance, so I can configure in the Amazon Web Console the Security Groups to firewall the service and let only the legit servers to access the zone entries instead of everybody in the Amazon Datacenter network.</p>

<p><em>&mdash;no-resolv</em> will avoid dnsmasq to read the list of name servers from <code>/etc/resolv.conf</code> and <em>&mdash;server=&ldquo;8.8.4.4&rdquo;</em> will provide a default one, in this case a Google nameserver</p>

<pre><code>/usr/sbin/dnsmasq --no-daemon --no-hosts --addn-hosts=/etc/hosts.acme --interface=eth0 --no-resolv --server="8.8.4.4"
</code></pre>

<h1>Setting up the DNS server</h1>

<p>Instead of launching the command manually, we will launch the service via <code>/etc/init.d/dnsmasq start|status|stop</code>. The default configuration is <code>/etc/dnsmasq.conf</code> and I have this there:</p>

<pre><code>no-resolv
server=8.8.4.4
server=8.8.8.8
interface=eth0
no-dhcp-interface=eth0
no-hosts
addn-hosts=/etc/hosts.acme
log-queries
log-dhcp
</code></pre>

<p>The <strong>user</strong> and <strong>group</strong> directives are not needed in Ubuntu, as the server is run always ad <strong>dnsmasq</strong> user. Only during testing we will use <strong>log-queries</strong> and <strong>log-dhcp</strong>, to see what is going on. Once finished the tests, we can remove them.</p>

<p>In <code>/etc/hosts.acme</code> just 1 entry (if you are copying tis, be sure of using a valid IP address, with numbers, not that z.z.z.z):</p>

<pre><code>z.z.z.z     server2.staging.acme
</code></pre>

<p>If I launch the service like <code>/usr/sbin/dnsmasq -C /etc/dnsmasq.conf --no-daemon</code> (as root) I get this:</p>

<pre><code>dnsmasq: started, version 2.59 cachesize 150
dnsmasq: compile time options: IPv6 GNU-getopt DBus i18n DHCP TFTP conntrack IDN
dnsmasq: using nameserver 8.8.8.8#53
dnsmasq: using nameserver 8.8.4.4#53
dnsmasq: read /etc/hosts.acme - 1 addresses
</code></pre>

<p>Then, from other server (IP: y.y.y.y) with access to port 53/udp of the server (name: server1.acme, IP: x.x.x.x) where dnsmasq is running, I do:</p>

<pre><code># dig @server1.acme www.google.de

; &lt;&lt;&gt;&gt; DiG 9.8.1-P1 &lt;&lt;&gt;&gt; @server1.acme www.google.de
; (1 server found)
;; global options: +cmd
;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 43199
;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0

;; QUESTION SECTION:
;www.google.de.                 IN      A

;; ANSWER SECTION:
www.google.de.          300     IN      A       74.125.24.94

;; Query time: 21 msec
;; SERVER: x.x.x.x#53(x.x.x.x)
;; WHEN: Tue Dec  3 16:35:58 2013
;; MSG SIZE  rcvd: 47
</code></pre>

<p>It seems the name server can resolve external domain names. And actually I see in the server:</p>

<pre><code>dnsmasq: query[A] www.google.de from y.y.y.y
dnsmasq: forwarded www.google.de to 8.8.4.4
dnsmasq: forwarded www.google.de to 8.8.8.8
dnsmasq: reply www.google.de is 74.125.24.94
</code></pre>

<p>So, it seems to be forwarding my requests to google&rsquo;s DNSs (8.8.4.4 and 8.8.8.8) as they are not in the cache of dnsmasq.</p>

<p>If I ask again (2 seconds later) for the same external name:</p>

<pre><code>dig @server1.acme www.google.de

; &lt;&lt;&gt;&gt; DiG 9.8.1-P1 &lt;&lt;&gt;&gt; @server1.acme www.google.de
; (1 server found)
;; global options: +cmd
;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 36570
;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0

;; QUESTION SECTION:
;www.google.de.                 IN      A

;; ANSWER SECTION:
www.google.de.          298     IN      A       74.125.24.94

;; Query time: 2 msec
;; SERVER: x.x.x.x#53(x.x.x.x)
;; WHEN: Tue Dec  3 16:36:00 2013
;; MSG SIZE  rcvd: 47
</code></pre>

<p>The answer I get has a TTL 2 seconds lower and in the server I see:</p>

<pre><code>dnsmasq: query[A] www.google.de from y.y.y.y
dnsmasq: cached www.google.de is 74.125.24.94
</code></pre>

<p>This time dnsmasq had the answer itself and didn&rsquo;t need to forward. In fact the query time went from 21msec to 2msec.</p>

<p>If I ask for an internal name:</p>

<pre><code>dig @server1.acme server2.staging.acme

; &lt;&lt;&gt;&gt; DiG 9.8.1-P1 &lt;&lt;&gt;&gt; @server1.acme server2.staging.acme;
; (1 server found)
;; global options: +cmd
;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 54617
;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0

;; QUESTION SECTION:
;server2.staging.acme.           IN      A

;; ANSWER SECTION:
server2.staging.acme.    0       IN      A       z.z.z.z

;; Query time: 2 msec
;; SERVER: x.x.x.x#53(x.x.x.x)
;; WHEN: Tue Dec  3 16:36:13 2013
;; MSG SIZE  rcvd: 53
</code></pre>

<p>I get this in the server:</p>

<pre><code>dnsmasq: query[A] server2.staging.acme from y.y.y.y
dnsmasq: /etc/hosts.acme server2.staging.acme is z.z.z.z
</code></pre>

<p>The server is also able to solve internal names.</p>

<h1>Automatising the installation with Puppet</h1>

<p>I have a <a href="https://gist.github.com/pfigue/7772289">Gist with an draft of a manifest</a> for Puppet.</p>

<p>Use <code>puppet apply --noop dnsmasq.pp</code> to check it (eventually w/o &mdash;noop).</p>

<h1>References:</h1>

<ul>
<li><a href="http://www.thekelleys.org.uk/dnsmasq/docs/dnsmasq-man.html">dnsmasq manual page</a></li>
<li><a href="http://en.wikipedia.org/wiki/Comparison_of_DNS_server_software">Comparison of DNS Server Software</a></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/12/04/replacing-dhcp-automatic-name-resolution-config-with-my-own-static-one/">Replacing DHCP automatic name resolution config with my own static one</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-12-04T13:07:00+01:00" pubdate data-updated="true">Dec 4<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><em>Problem1:</em> I have an AWS EC2 Instance (Ubuntu 12.04) where I want to use <a href="http://pfigue.github.io/blog/2013/12/06/configuring-dnsmasq-to-serve-my-own-domain-name-zone/">my own DNS service</a>, not the default one provided by Amazon.</p>

<p><em>Solution1:</em> Definining a static DNS server configuration</p>

<p>In <code>/etc/network/interfaces</code> you can specify <strong>dns-search</strong> and <strong>dns-nameservers</strong> in the configuration of the network interface,</p>

<pre><code># The primary network interface
auto eth0
iface eth0 inet dhcp
        dns-search acme
        dns-nameservers 1.2.3.4
</code></pre>

<p>Now if you apply this configuration with <code>/etc/init.d/networking restart</code>, you will be able to see changes in <code>/etc/resolv.conf</code>.</p>

<p><em>Note1:</em> Restarting the network services didn&rsquo;t disconnect me from the computer I was configuring.</p>

<p><em>Note2:</em> There may be better ways to apply changes in the network config.</p>

<p><em>Problem2:</em> In /etc/resolv.conf there is my static configuration <strong>together with the DNS setup received via DHCP</strong>, and I want only my configuration without the one provided by DHCP.</p>

<p><em>Solution2:</em> Avoid the DNS setup from DHCP.</p>

<p>My system is using dhclient3, and the config. file for it is in <code>/etc/dhcp/dhclient.conf</code>. There, I comment the options to retrieve the DNS config from the DHCP service:</p>

<pre><code>request subnet-mask, broadcast-address, time-offset, routers,
        #domain-name, domain-name-servers, domain-search, host-name,
        netbios-name-servers, netbios-scope, interface-mtu,
        rfc3442-classless-static-routes, ntp-servers,
</code></pre>

<p>Now if I restart the <code>networking</code> service again, <code>/etc/resolv.conf</code> will have the right domain and nameservers.</p>

<p>References:</p>

<ul>
<li><a href="http://ubuntuforums.org/showthread.php?t=1320773">Static DNS with DHCP</a></li>
<li><a href="https://help.ubuntu.com/12.04/serverguide/network-configuration.html#name-resolution">Ubuntu 12.04: Network Configuration: Name Resolution</a></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/11/29/a-puppet-manifest-to-set-the-timezone/">A Puppet Manifest to set the timezone</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-11-29T16:48:00+01:00" pubdate data-updated="true">Nov 29<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I am getting to know Puppet and right now I would like to set the timezone of my servers in an automated way via Puppet Manifests.</p>

<h1>Ensuring the presence and content of a file</h1>

<p>I created a new file <code>timezone.pp</code> and wrote inside:</p>

<pre><code>file { '/etc/timezone':
    ensure =&gt; present,
    content =&gt; "Europe/Berlin\n",
}
</code></pre>

<p>Saved it, and run <code>puppet apply --noop timezone.pp</code> as root. The <em>&mdash;noop</em> is to indicate puppet that I want a dry-run, to not make any changes into the system, just validate the Manifest.</p>

<p>Those 4 lines define a <a href="http://docs.puppetlabs.com/references/latest/type.html#file">ressource type file</a>, the name of the ressource and (in this case) also the path of the file is <em>/etc/timezone</em>, the file should be present into the filesystem and the content should be the indicated one.</p>

<p>With the file ressource I could also define symbolic links, directories, etc.</p>

<p>Once the validation with <code>puppet apply --noop</code> was okay, I moved to the next step.</p>

<h1>Running an external command</h1>

<p>With the <em>exec</em> ressource I can run a command as a given user. The command should be expressed as an absolute path, so <code>/usr/sbin/dpkg-reconfigure</code> instead of <code>dpkg-reconfigure</code>:</p>

<pre><code>exec { 'reconfigure-tzdata':
        user =&gt; root,
        group =&gt; root,
        command =&gt; '/usr/sbin/dpkg-reconfigure --frontend noninteractive tzdata',
}
</code></pre>

<p>Also note that the <a href="https://help.ubuntu.com/community/UbuntuTime#Using_the_Command_Line_.28unattended.29">command won&rsquo;t require input from the user</a> and it will be run as root.</p>

<h1>Reporting and being talkative</h1>

<p>To keep the user updated and make the debugging easier, I would like to notify the user what is going on:</p>

<pre><code>notify { 'timezone-changed':
        message =&gt; 'Timezone was updated to Europe/Berlin',
}
</code></pre>

<p>This ressource will be named <code>timezone-changed</code> and represents a notification message. There are also fail{} and notice{} ressources, afaik.</p>

<h1>Execution order</h1>

<p>Puppet Manifests are declarative. You just write down statement of what do you want to get, not how to get it.</p>

<p>Now I want to express that the <em>timezone-changed notify ressource</em> should be executed only after the <em>reconfigure-tzdata exec ressource</em>. And this one should be executed only after <em>/etc/timezone file ressource</em>:</p>

<pre><code>File['/etc/timezone'] -&gt; Exec['reconfigure-tzdata'] -&gt; Notify['timezone-changed']
</code></pre>

<p>So, if /etc/timezone already exists and has the right contents and (in general) meets the specification of the ressource we wrote in the manifest, no reconfigure-tzdata will be executed and no notification will happen.</p>

<h1>Applying the changes</h1>

<p>Having all the previous ressources and ordering in <a href="https://gist.github.com/pfigue/7694021">timezone.pp</a>, as root I run <code>puppet apply timezone.pp</code>:</p>

<pre><code>notice: /Stage[main]//File[/etc/timezone]/content: content changed '{md5}4f24b133ba38d8fd565168742c9aedeb' to '{md5}749357f70f40574f632071ec7d5f41a9'
notice: /Stage[main]//Exec[reconfigure-tzdata]/returns: executed successfully
notice: Timezone was updated to Europe/Berlin
notice: /Stage[main]//Notify[timezone-changed]/message: defined 'message' as 'Timezone was updated to Europe/Berlin'
notice: Finished catalog run in 1.16 seconds
</code></pre>

<p>Checking:</p>

<pre><code># date
Thu Nov 28 16:10:51 CET 2013
#
</code></pre>

<p>Time zone is now <em>CET</em> which is Berlin, which is right.</p>

<h1>References:</h1>

<ul>
<li><a href="https://help.ubuntu.com/community/UbuntuTime#Using_the_Command_Line_.28unattended.29">Unattended timezone change in Ubuntu</a></li>
<li><a href="http://docs.puppetlabs.com/references/latest/type.html">List of Ressources for Puppet</a></li>
<li><a href="http://docs.puppetlabs.com/learning/ordering.html">Ressource Ordering in Puppet</a></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/11/28/a-custom-facter-fact-to-read-aws-user-data/">A custom Facter fact to read AWS User-Data</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-11-28T12:35:00+01:00" pubdate data-updated="true">Nov 28<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>I need to do the provisioning of some AWS EC2 Instances depending on their role.</h2>

<p>Some of them will need to install some packages with some configuration, others will need different packages and different configuration, depending on the role they will adopt in the new system.</p>

<p>For this reason I need Puppet to behave in a different way depending on a <strong>fact</strong>, the <em>server flavour</em> of the server who is being provisioned.</p>

<h2>How to communicate the role to Puppet</h2>

<p>The first exercise would be to learn how <a href="http://pfigue.github.io/blog/2013/11/27/how-to-add-custom-facts-to-facter/">to write a new dummy fact for Facter</a>, so we are sure we can write facts for Puppet.</p>

<p>The second goal would be to write a new fact that actually reads the role of the server.</p>

<h3>Appending custom information to an EC2 instance.</h3>

<p>I communicate the role (and other information) to a new server <strong>via User-Data</strong>, whenever I <em>Launch a New Instance</em> from the AWS Web Console.
During the 3rd step, named <em>Configure Instance Details</em>, I have the option to define <em>Advanced Details</em>, one of them the <em>User data</em>.</p>

<p>Once the instance is running, I <strong>can&rsquo;t change that User-Data</strong>. If I want to, I need to destroy that instance and create a new one with the new data.</p>

<p>An <strong>alternative to User-Data is to use <em>Tags</em></strong>, and then the EC2 Command-Line Tools to access and read information from those Tags. But you should mind that there is a <strong>limit of 10 tags per server</strong>, so it may not be the best solution. On the other hand, <strong>you can change the tags while the Instance is running</strong>. No need to destroy it.</p>

<p>I upload a YAML file with all the information, and then, once the new EC2 Instance is up, from the instance itself I can get that YAML file:</p>

<pre><code>$ /usr/bin/curl --silent "http://169.254.169.254/latest/user-data/"
instance:
    flavor: application-server
$
</code></pre>

<p>With <a href="https://gist.github.com/pfigue/7690424">some python scripting like</a>:</p>

<pre><code>import sys
import yaml

if __name__ == '__main__':
    contents = sys.stdin.read()
    document = yaml.load(contents)
    for key in sys.argv[1:]:
            try:
                    document = document[key]
            except KeyError:
                    sys.exit(1)
    sys.stdout.write(str(document))
    sys.stdout.flush()
    sys.exit(0)
</code></pre>

<p>I can provide the script the YAML via stdin and then ask for some data:</p>

<pre><code>$ curl --silent "http://169.254.169.254/latest/user-data/" | python ./ec2-user-data-parser.py instance flavor
application-server
$
</code></pre>

<h3>Writting the Facter <em>fact</em></h3>

<p>Writting a new fact is now straight forward (I saved the python script in <code>/root/tools/ec2-user-data-parser.py</code>):</p>

<pre><code># server_flavor.rb

Facter.add("server_flavor") do
  setcode do
    Facter::Util::Resolution.exec('/usr/bin/curl --silent "http://169.254.169.254/latest/user-data/" | /usr/bin/python /root/tools/ec2-user-data-parser.py instance flavor')
  end
end
</code></pre>

<p>I save the code to <code>/root/facter/server_flavor.rb</code> and then test it:</p>

<pre><code>$ FACTERLIB=/root/facter/ facter server_flavor
application-server
$
</code></pre>

<p>I may need still to add some <code>export FACTERLIB=/root/facter/</code> to <code>/root/.bashrc</code>, but now my puppet manifests will know which kind of Amazon servers they are provisioning.</p>

<h2>References:</h2>

<ul>
<li><a href="https://gist.github.com/pfigue/7690424">The code in a Gist</a></li>
<li><a href="http://docs.puppetlabs.com/guides/custom_facts.html">Puppet Docs: Custom Facts</a></li>
<li><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AESDG-chapter-instancedata.html">AWS Instance Meta- and User- Data</a></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/11/27/how-to-add-custom-facts-to-facter/">How to add custom facts to Facter</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-11-27T18:55:00+01:00" pubdate data-updated="true">Nov 27<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>What is Facter?</h2>

<p>It is a Ruby tool that informs you about facts.</p>

<p>As far as I know, it is used often from Puppet, to know about properties of the environment you are going to provision.</p>

<p>Those properties can be things like <em>Operating System</em>, <em>Version of the kernel</em>, <em>Architecture</em>, <em>Amazon EC2 Instance ID</em>, <em>Available memory</em>, <em>Number of processors</em>, etc.</p>

<p>The <code>facter</code> tool by default has some values like those above: you can run <code>facter</code> in the shell to get a list of <em>facts</em>.</p>

<p>From a Puppet Manifest you could write statements dependent on those facts.
For example, to install some package when the manifest is applied to a Debian system, and install a different package when applied to a Red Hat one.</p>

<h2>Do you need to define your own Facts?</h2>

<p><strong>Facter</strong> looks for the <em>FACTERLIB</em> environment variable, which may point to a directory, if it is defined.</p>

<p>If you put in that directory a file named <code>hardware_platform.rb</code> (note the <em>.rb</em> extension), and inside you define:</p>

<pre><code># hardware_platform.rb

Facter.add("hardware_platform") do
    setcode do
        Facter::Util::Resolution.exec('/bin/uname -i')
    end
end
</code></pre>

<p>There will appear a new <em>Fact</em> called <em>hardware_platform</em>:</p>

<pre><code># facter | grep -i platform
hardware_platform =&gt; x86_64
#
</code></pre>

<p>You can invoke it also via <code>facter hardware_platform</code>:</p>

<pre><code># facter hardware_platform
x86_64
#
</code></pre>

<p>Pay attention, that the file name and the Fact name are the same. An the file extension is <em>.rb</em>.</p>

<p>In this way, you can have your own facts for your Puppet manifests.</p>

<p>Puppet Docs has much <a href="http://docs.puppetlabs.com/guides/custom_facts.html">more information</a>.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/09/24/versioning-apis-do-or-dont/">Versioning APIs: do or don&#8217;t</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-09-24T00:27:00+02:00" pubdate data-updated="true">Sep 24<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Today I visited <a href="https://secure.trifork.com/berlin-2013/freeevent/index.jsp?eventOID=5783">REST Beyond the Intro Level</a>, where <a href="http://www.innoq.com/blog/st/">Stefan Tilkov</a> explained several concepts regarding REST APIs.</p>

<p>Among other things he mentioned NOT to version APIs, and he took as argument the <a href="http://en.wikipedia.org/wiki/Robustness_principle">Postel&rsquo;s Law</a>:</p>

<pre><code>Be conservative in what you send, be liberal in what you accept
</code></pre>

<p>Keep your API always backwards compatible. Keep te same behaviour for your ressources, and if you can&rsquo;t keep it, create new ressources.</p>

<p>His idea is that the part of the system serving the API should be <em>conservative</em>, and should avoid <em>semantic jumps</em> when developers deploy new features. At the same time, the consumers of the API should be tolerant when they use it.</p>

<h2>Stefan, I disagree</h2>

<p>If Stefan has a point when he says that an API is always the same and it has the same essential behaviour (e.g. behind the <a href="https://dev.twitter.com/docs/api">Twitter REST API</a> is the same idea, independently of the version: essentially, provide access to read and post tweets.), personally I don&rsquo;t agree with him too much.</p>

<p>I think an API evolves a lot during its life and needs proper versioning. At least, the non-backwards compatible changes should be identified.</p>

<p>In a mature API, well designed, well and long tested, maybe there are no big changes. But in a <strong>new API, built for a not-very-well defined product, change is the constant, and non-backwards-compatible changes happen</strong>.</p>

<p>Also there could be plenty of different clients for an API, each of them programmed for a different version and expecting an specific behaviour. They will break if we don&rsquo;t serve different versions of the API.</p>

<ul>
<li>One alternative is put the version number in the URL, like <a href="http://api.v1.foo.bar/,">http://api.v1.foo.bar/,</a> or <a href="http://api.foo.bar/v1/">http://api.foo.bar/v1/</a></li>
<li>Another alternative (I like it more) it passing an argument with the version, like <a href="http://api.foo.bar/?v=1,">http://api.foo.bar/?v=1,</a> and default to the last stable version if no version number is provided.</li>
</ul>


<p>My work experience is <em>startup</em>, and there you don&rsquo;t know always which product are you developing. Decissions change often quite fast and you can&rsquo;t design for the long-term. Maybe if I had work in a more stable environment I had a different opinion and could easily agree with Stefan.</p>

<h2>Semantic Versioning</h2>

<p><a href="http://semver.org/">Semantic Versioning</a> is a nice schema to start: Major version number for uncompatible changes, Minor version for new features and Patch number for bugfixes.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/09/21/monitoring-software/">Monitoring software</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-09-21T23:59:00+02:00" pubdate data-updated="true">Sep 21<span>st</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><ul>
<li>Pandora FMS</li>
<li>Icinga/Nadios</li>
<li>Riemann</li>
<li>Splunk</li>
<li>Munin</li>
<li>Cacti</li>
<li>New Relic</li>
<li>Zabbix</li>
<li>OpenNMS</li>
<li>Ganglia</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/08/19/deploying-static-pages/">Deploying static pages</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-08-19T19:16:00+02:00" pubdate data-updated="true">Aug 19<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>A external designer prepares some static pages as landing pages for a platform.</p>

<ul>
<li>They are stored in a github repository.</li>
<li>We should provide a comfortable way of deploying them to production.</li>
<li>Obviously, the external desginer is not allowed to access the production environment.</li>
</ul>


<p>Solution:</p>

<ul>
<li>we will provide github access to the repository, so the desginer will push/pull directly to github the change she does.</li>
<li>we will write a deployment script to fetch the last changes from github and put them in production</li>
</ul>


<h2>The deployment script</h2>

<p>Something very easy in shell script: fetch the last changes, clean the filetree and copy it to production</p>

<pre><code>#!/bin/bash

GIT_COPY=/opt/acme/repo-static-pages/
TARGET=/usr/share/nginx/www/
TMP_DIR=/tmp/repo-static-pages/


### Update local copy
pushd $GIT_COPY &gt; /dev/null
git fetch upstream
git checkout master
git pull upstream master
popd &gt; /dev/null

### Put to a temporary location and clean it
rm -rf $TMP_DIR
mkdir -p $TMP_DIR
cp -r $GIT_COPY* $TMP_DIR
find $TMP_DIR -iname ".git" -type d -exec rm -rf {} \;
find $TMP_DIR -iname "*.tar.gz" -type f -delete
find $TMP_DIR -iname "*.tar" -type f -delete

### Deploy
rm -rf $TARGET
mkdir $TARGET
cp -r $TMP_DIR* $TARGET

rm -rf $TMP_DIR 
</code></pre>

<p>Note that it will deploy the <em>master</em> branch.</p>

<p>Also, we have to prepare the environment:</p>

<ul>
<li>Create SSH keys that will be used as <strong>deployment keys</strong> for the repository: <code>ssh-keygen -t rsa</code>

<ul>
<li> Without password to be able to automatise the process.</li>
<li> Or with password and store the unencrypted key in an SSH keyring.</li>
</ul>
</li>
<li><code>mkdir -p /opt/acme/repo-static-pages/</code></li>
<li><code>git clone git@github.com:acme/repo-static-pages.git /opt/acme/repo-static-pages/</code></li>
<li><code>git remote add upstream git@github.com:acme/repo-static-pages.git</code></li>
</ul>


<p>Note that the <em>upstream</em> should use the SSH endpoint instead the HTTPS one, to be able to authentify via the <em>deployment key</em>.</p>

<h2>Deploying</h2>

<p>Alternatives:</p>

<ul>
<li>deploy manually on demand, but I would prefer to spend the time in something more interesting</li>
<li>Install a cronjob that weekly, daily or every 5 minutes will deploy the last changes in github.</li>
<li>Use a githook that will run the deployment when a Pull Request is merged into the master branch of the repo.</li>
</ul>


<p>In any case, we have to be sure that no several deployments are running concurrently.</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <ul id="recent_posts">
      <li class="post">
      <a href="http://pfigue.github.io" alt="Home"><img src="/images/Home.png"></a>
      <a href="http://pfigue.github.io/archives/" alt="Archives"><img src="/images/Calendar.png"></a>
      <a href="mailto:" alt="E-Mail"><img src="/images/Envelope.png"></a>
      <a href="http://pfigue.github.io/atom.xml" alt="subscribe feed"><img src="/images/rss_big.png"></a>
      </li>
  </ul>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2014/01/25/using-vagrant-with-lxc-linux-containers/">Using Vagrant with LXC Linux Containers</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/01/25/my-first-steps-with-vagrant/">My first steps with Vagrant</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/12/06/configuring-dnsmasq-to-serve-my-own-domain-name-zone/">Configuring dnsmasq to serve my own domain name zone</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/12/04/replacing-dhcp-automatic-name-resolution-config-with-my-own-static-one/">Replacing DHCP automatic name resolution config with my own static one</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/11/29/a-puppet-manifest-to-set-the-timezone/">A Puppet Manifest to set the timezone</a>
      </li>
    
  </ul>
</section>


<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("__pfigue", 4, false);
    });
  </script>
  <script src="/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/__pfigue" class="twitter-follow-button" data-show-count="false">Follow @__pfigue</a>
  
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - pfigue -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'pfigue';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>





  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
