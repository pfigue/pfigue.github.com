
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>pfigue</title>
  <meta name="author" content="pfigue">

  
  <meta name="description" content="ElasticSearch consumes an high number of file descriptors. It is quite easy to break an ES cluster by having a low number of available
file &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://pfigue.github.com/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="pfigue" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>


  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-38745757-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:pfigue.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/pfigue/">About me</a></li>
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/categories/talk">Talks</a></li>
  <li><a href="/blog/categories/note">Notes</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/03/06/file-descriptors-and-elasticsearch/">File Descriptors and ElasticSearch</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-03-06T16:07:00+01:00" pubdate data-updated="true">Mar 6<span>th</span>, 2015</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>ElasticSearch consumes an high number of file descriptors.</h1>

<p>It is quite easy to break an ES cluster by having a low number of available
file descriptors.</p>

<p>When accessing indices ES will use FDs, but when connecting
with other members of the cluster or with clients, it will need also to create
sockets, and therefore, to use FDs.</p>

<p>In the web I read often 65000 as the minimal number of available FD that should
be provided. In my systems I use to configure at least one million.</p>

<h1>How to check information about file descriptors?</h1>

<h2>Via REST API</h2>

<p>We can ask each node about information on the cluster nodes:</p>

<pre><code>$ curl -s "http://127.0.0.1:9200/_nodes/process?pretty"
[...]
"v5_G7FNvRBOLpS1MMByX4w": {
    "process": {
    "mlockall": true,
**  "max_file_descriptors": 200000,**
    "id": 2165,
    "refresh_interval_in_millis": 1000
},
"name": "elastic2",
[...]
</code></pre>

<p>Or if we know the identifier of a node we can also filter:</p>

<pre><code>$ curl -s "http://127.0.0.1:9200/_nodes/process?pretty" | jq '.nodes.rsYeYNh2STqF5KyzFiUFqQ.process.max_file_descriptors'
200000
</code></pre>

<p>Maybe <a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/cat.html">one of the <em>cat</em> APIs</a> has some way of reporting current number of used FDs, instead of the max, which is what I can see in the previous call.</p>

<h2>With ElasticSearch Plugins</h2>

<p>ElasticSearch has some so-named <a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/modules-plugins.html#site">site plugins</a>:</p>

<ul>
<li>With <a href="https://github.com/royrusso/elasticsearch-HQ">HQ</a> I can see the number of currently <strong>opened file descriptors</strong>.</li>
<li>With <a href="https://github.com/lukas-vlcek/bigdesk">BigDesk</a> I have a graph of the <strong>number of FD</strong> and the <strong>max allowed FDs</strong>.</li>
<li>With <a href="https://github.com/mobz/elasticsearch-head">Head</a> we just have the same information we can have asking the API from the command line.</li>
</ul>


<h2>With the ProcFS</h2>

<p>Or in each server we can get the PID of each ES instance and ask the procfs
about the <strong>effective limits</strong>:</p>

<pre><code>$ ps aux | grep java
elastic+ 17586 17.4 54.9 8102680 4225596 ?     SLl  Mar04 522:30 /usr/bin/java -Xms3584M -Xmx3584M [...]
$
$ cat /proc/17586/limits
Limit                     Soft Limit           Hard Limit           Units     
Max cpu time              unlimited            unlimited            seconds   
Max file size             unlimited            unlimited            bytes     
Max data size             unlimited            unlimited            bytes     
Max stack size            8388608              unlimited            bytes     
Max core file size        0                    unlimited            bytes     
Max resident set          unlimited            unlimited            bytes     
Max processes             59935                59935                processes 
**Max open files            200000               200000               files**
Max locked memory         unlimited            unlimited            bytes     
Max address space         unlimited            unlimited            bytes     
Max file locks            unlimited            unlimited            locks     
Max pending signals       59935                59935                signals   
Max msgqueue size         819200               819200               bytes     
Max nice priority         0                    0                    
Max realtime priority     0                    0                    
Max realtime timeout      unlimited            unlimited            us
$
</code></pre>

<p>That figure is the important one, when configuring limits for an ES server.</p>

<h2>System calls: getrlimit and prlimit</h2>

<p>The <code>getrlimit</code> and <code>prlimit</code> system calls can be also used to fetch the current
and maximal figures of file descriptors.</p>

<h1>How to configure the number of total available FDs</h1>

<h2>System-wide configuration</h2>

<p>Via SysFS we can tune those kernel parameters[9] that affect the entire system:</p>

<pre><code>$ sysctl fs.file-nr
fs.file-nr = 9984       0       1149332
</code></pre>

<p>Where 9984 is the current number of opened file descriptors.
<code>man sysctl</code> can throw some help on how to change the max number.</p>

<h2>Shell session configuration</h2>

<p>The shell imposes another additional limitation to the users and its processes
via ulimit [10]:</p>

<pre><code>$ ulimit -n
1000000
</code></pre>

<p>Any process I launch in this shell session inherits that limit and can open so
many FD as it wants solong neither this limit nor the kernel limit are surpassed.</p>

<h2>PAM authentication</h2>

<p>The file <code>/etc/security/limits.conf</code> can contain some rules like:</p>

<pre><code>* soft nofile 1024000
* hard nofile 1024000
</code></pre>

<p>to define soft and hard limits for the number of files.</p>

<p>Changes in this file require the users to log out and log in again to take
effect [10].</p>

<p>Nonetheless, not every process is controlled by these PAM rules. Afaik, only
processes which were born in a login shell[4] will inherit these limits.</p>

<p>Processes started from Upstart do not inherit these limits. See [3].</p>

<h2>Upstart tasks</h2>

<p>The <em>stanza</em> <code>limit nofile 4096 4096</code>[1] in the Upstart task in /etc/init/ sets
the limit for the processes started in the Upstart job.</p>

<p>Note that the PAM limits (<code>/etc/security/limits.conf</code>) are not applied to these
jobs, so this <code>limit</code> statement is the only way to be sure these processes will
have enough FD available.</p>

<p>See [2] and [3].</p>

<h2>ElasticSearch configuration</h2>

<p>I can see <code>MAX_OPEN_FILES=200000</code> in <code>/etc/default/elasticsearch</code>. That file is
read whenever <code>/etc/init.d/elasticsearch</code> is run, and that parameter is applied
to <code>ulimit -n</code>, so be sure you write there a meaningful number.</p>

<h2>Tweaking a running process</h2>

<p>The same as we could read the limits for a process with <code>prlimit</code> or <code>getrlimit</code>
system calls, we can also set those limits with <code>prlimit</code> or <code>setrlimit</code>.</p>

<p>If we don&rsquo;t want to implement a program to use those system calls we can:</p>

<pre><code>1. Use the `prlimit` command of the util-linux package.
2. Use a short [solution Lars Windolf wrote](http://lzone.de/Debian%20Ubuntu%20ulimit%20Check%20List)[5,6]
</code></pre>

<p>To use the <code>prlimit</code> command[7] you will need <code>util-linux</code> package[8] installed, version >=2.21.
Ubuntu 14.04 is currently lacking this program as it uses version 2.20.</p>

<p>The great advantage of this system calls is that we don&rsquo;t need to restart the
process to change the limits.</p>

<h1>Refs/Notes</h1>

<ol>
<li><a href="http://upstart.ubuntu.com/wiki/Stanzas#limit">Official Upstart Stanzas Doc &ndash; limit</a></li>
<li><a href="http://bryanmarty.com/2012/02/10/setting-nofile-limit-upstart/">Setting the nofile limit in upstart</a></li>
<li><a href="https://coderwall.com/p/myodcq/setting-max-file-descriptors-and-other-limits-with-upstart-on-debian-ubuntu">Setting max file descriptors and other limits with upstart on debian/ubuntu</a></li>
<li>and maybe those from SysV init.d[3], although my ES service runs from <code>/etc/init.d/elasticsearch</code> and follows the same limits as Upstart tasks (Ubuntu 14.04)</li>
<li><a href="http://lzone.de/Debian%20Ubuntu%20ulimit%20Check%20List">The Debian/Ubuntu ulimit Check List</a></li>
<li><a href="https://gist.github.com/pfigue/976d781c282d7780412d">Gist &ndash; set_limit_nofile.c</a></li>
<li><a href="http://manpages.courier-mta.org/htmlman1/prlimit.1.html">Manpage &ndash; prlimit</a></li>
<li><a href="https://github.com/karelzak/util-linux">Github: util-linux is a random collection of Linux utilities</a></li>
<li><a href="http://www.cyberciti.biz/tips/linux-procfs-file-descriptors.html">Linux: Find Out How Many File Descriptors Are Being Used</a></li>
<li><a href="http://www.unixmantra.com/2013/06/resource-limits-on-unix-systems-ulimit.html">Resource limits on UNIX systems (ulimit)</a></li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/04/02/bulk-user-creation-in-vbulletin-5-with-casperjs/">Bulk user creation in vBulletin 5 with CasperJS</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-04-02T20:48:00+02:00" pubdate data-updated="true">Apr 2<span>nd</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>The Problem</h2>

<p>I had to create around 2000 users into a forum running with vBulletin 5.</p>

<p>I saw 3 options:</p>

<ul>
<li> Using vBulletin API, but for version 5 it is not yet documented at the time of writing this. One alternative is to reverse engineer it with help of version 4 docs., but this is not the fastest.</li>
<li> Accesing directly the database and creating there the needed rows, but I had no access to the database, and a little bit of reversing is probably needed to understand the dependences between the different tables.</li>
<li> Use PhantomJS/CasperJS/python-mechanize to manipulate the interface in an automated way. The interface had some Javascript, so python-mechanize would be excluded. CasperJS (a framework, running over PhantomJS) is the option I chose.</li>
</ul>


<h2>CasperJS</h2>

<p>I have never used it before, neither PhantomJS, so I didn&rsquo;t know how complicated it would be. <a href="http://docs.casperjs.org/en/latest/installation.html">Fortunately, it was quite easy and fast to setup</a>.</p>

<p>This is the script I used, which can be used as <code>casperjs script.js "newuser_username" "newuser_password" "newuser_email"</code></p>

<pre><code>var casper = require('casper').create();

casper.start('http://&lt;URL to the forum&gt;/admincp/', function() {
    this.echo(this.getTitle()); // Some logging to know if the script is running
    console.log(casper.cli.args[0])
    console.log(casper.cli.args[1])
    console.log(casper.cli.args[2])
    this.fill('form[action="../login.php?do=login"]',
        {
            'vb_login_username':'&lt;An Admin Username&gt;',
            'vb_login_password': '&lt;Admin\'s password&gt;,
    },
    true);
});

casper.thenOpen('http://&lt;URL to the forum&gt;/admincp/user.php?do=add&amp;', function(){
    this.echo(this.getTitle()); // Some logging to know if the script is running
    this.fill('form[action="user.php?do=update"]',
        {
            'user[username]': casper.cli.args[0],
            'password': casper.cli.args[1],
            'user[email]': casper.cli.args[2],
            'user[membergroupids][]': ['14', '12'],  // List of group numbers (actually, strings) the user belongs to.
        },
        true);
});

casper.then(function() {
    this.echo(this.getTitle());  // Some logging to know if the script is running
//    console.log(casper.cli.args[0])
});

casper.run();
</code></pre>

<h2>Results</h2>

<p>First I tried creating one user, then creating three, then all the 2000 users. It needs around 10 or 15 seconds per user, so it is not the fastest solution, but the simplest I had.</p>

<p>The script can be called several times with identical parameters and the result will be the same.</p>

<p>Running several instances in parallel can also be an alternative.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/02/04/creating-a-new-profile-for-lintian/">Creating a new profile for Lintian</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-02-04T09:56:00+01:00" pubdate data-updated="true">Feb 4<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Lintian is a tool to check the format of Debian Packages.</p>

<p>It is useful when you are building your own packages, to check if they are properly built before testing them by actually installing them (for example, <a href="http://pfigue.github.io/blog/2014/01/25/using-vagrant-with-lxc-linux-containers/">through Vagrant into fresh containers</a>).</p>

<p>It can use different profiles, with different checks. The default profile is <strong>debian/main</strong>, which is useful if you pretend to package a program for the official Debian repositories.</p>

<p>After installing <strong>Lintian</strong> with <code>sudo apt-get install lintian</code> in Ubuntu 12.04, I have a file <code>/usr/share/lintian/profiles/debian/main.profile</code>. That is the definition of the <em>debian/main</em> profile (or just <em>debian</em>).</p>

<p>Lintian looks for profiles in this order,</p>

<ul>
<li> first in the user&rsquo;s domain <code>$HOME/.lintian/profiles/</code></li>
<li> then in system&rsquo;s domain <code>/etc/lintian/profiles</code></li>
<li> and finally in <code>/ur/share/lintian/profiles</code>.</li>
</ul>


<p>So, what I did is creating a new profile, (filename ended in <em>.profile</em>):</p>

<pre><code>$ mkdir -p /home/pfigue/.lintian/acme_gmbh/my_cute_profile/
$ vim /home/pfigue/.lintian/acme_gmbh/my_cute_profile/main.profile
</code></pre>

<p>There, the content of the profile file in my case is:</p>

<pre><code>Profile: acme_gmbh/main
Extends: debian/main
Disable-Tags: dir-or-file-in-opt
</code></pre>

<p>Which actually inherits all the rules from debian/main, and disables the check to avoid installation in <code>/opt/</code> (dir-or-file-in-opt). That path is reserved for private software, not for Debian software, that&rsquo;s the reason why the Debian profile checks nothing is installed there.</p>

<p>Once the new profile is in place, you can check it with:</p>

<pre><code>$ lintian --profile acme_gmbh  /tmp/testapp_0.45_amd64.deb
</code></pre>

<p>Per default the profile <em>acme_gmbh</em> is an alias for <em>acme_gmbh/main</em>.</p>

<p>References:</p>

<ul>
<li> <a href="http://lintian.debian.org/manual/section-2.5.html">Lintian User&rsquo;s Manual: Vendor Profiles</a></li>
<li> <a href="http://pfigue.github.io/blog/2014/01/25/using-vagrant-with-lxc-linux-containers/">Using Vagrant with LXC Linux Containers</a></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/01/25/using-vagrant-with-lxc-linux-containers/">Using Vagrant with LXC Linux Containers</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-01-25T15:44:00+01:00" pubdate data-updated="true">Jan 25<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>Containers</h2>

<p>LXC Containers are a relatively new way of virtualization for Linux environments. Solaris had containers since several years ago, but in Linux they appeared around 5 years ago, afaik.</p>

<p>The point of virtualizing using containers instead of virtual machines is that, both, guest and host, use the same instance of the kernel, which translates in <strong>far less time to boot and far less resources used</strong>.</p>

<p>A container is just a set of resources and processes running in a different namespace, eventually with some limitations (CPU or I/O usage, memory used, etc.).</p>

<p>Afair, there are/were 2 implementations of containers for linux: OpenVZ and LXC. Without being an expert in the area, I&rsquo;d say that LXC has much better maintenance nowadays than OpenVZ.</p>

<h2>LXC Containers in Ubuntu</h2>

<p>In Ubuntu 12.04 we can install LXC as usual with <code>sudo apt-get install lxc</code>. As root, we can list the containers we have in every state with <code>sudo lxc-list</code>.</p>

<p>Usually, <a href="https://help.ubuntu.com/lts/serverguide/lxc.html#lxcbr0">once <strong>lxc</strong> is installed, we should find a new network bridge</a>: <em>lxcbr0</em>. You can check if it is present with:</p>

<pre><code>$ ifconfig lxcbr0 2&gt; /dev/null 1&gt;&amp;2  &amp;&amp; echo 'lxc interface is present' || echo 'no lxc interface'
lxc interface is present
$
</code></pre>

<p>Before start to use containers with Vagrant, we should <a href="https://github.com/fgrehm/vagrant-lxc/wiki/Avoiding-%27sudo%27-passwords">work around a bug in sudo (Ubuntu 12.04)</a>.</p>

<p>With <code>sudo visudo</code> you can add the line:</p>

<pre><code>Defaults        !tty_tickets
</code></pre>

<p>to the sudoers file. It will solve the bug.</p>

<h2>Vagrant with the LXC provider</h2>

<p>Let&rsquo;s create a new vagrant project:</p>

<pre><code>$ mkdir vagrant-lxc
$ cd vagrant-lxc/
$ vagrant init test-lxc http://dl.dropbox.com/u/13510779/lxc-precise-amd64-2013-07-12.box
</code></pre>

<p>Where the URL is an <a href="http://dl.dropbox.com/u/13510779/lxc-precise-amd64-2013-07-12.box">Ubuntu 12.04 amd64 box <strong>for LXC</strong></a> from <a href="http://vagrantbox.es/">vagrantbox.es</a>.</p>

<p>You can use the same <a href="http://pfigue.github.io/blog/2014/01/25/my-first-steps-with-vagrant/">Vagrantfile I used in the previous article</a>, but notice that the <code>config.vm.network</code> parameter is ignored by this provider.
At the moment you can only forward port, but not bridge any interface.</p>

<p>Now you can <a href="https://github.com/fgrehm/vagrant-lxc/blob/master/README.md">install there the <strong>vagrant-lxc</strong> plugin</a> with <code>vagrant plugin install vagrant-lxc</code>.</p>

<p>Once done you should already be able to fire up that box with LXC:</p>

<pre><code>$ vagrant up --provider=lxc
[default] Warning! The LXC provider doesn't support any of the Vagrant public / private
network configurations (ex: `config.vm.network :private_network, ip: "some-ip"`).
They will be silently ignored.
</code></pre>

<p><code>vagrant ssh</code> from the same <code>vagrant-lxc/</code> directory to check it, or <code>sudo lxc-list</code> or <code>lxc-ps --lxc</code> to visualice the running containers.</p>

<h2>Advantages</h2>

<p>The time needed to boot up a Vagrant box with LXC is really much lower than using VirtualBox. This translates in faster try-error loop, faster feedback and <a href="http://pfigue.github.io/blog/2014/01/25/my-first-steps-with-vagrant/">faster development of Puppet Manifest, server configuration</a>, <a href="http://pfigue.github.io/blog/2014/01/25/my-first-steps-with-vagrant/">faster testing of packages</a>, etc.</p>

<p>References:</p>

<ul>
<li> <a href="https://help.ubuntu.com/lts/serverguide/lxc.html#lxcbr0">LXC &ndash; lxcbr0</a></li>
<li> <a href="https://github.com/fgrehm/vagrant-lxc/blob/master/README.md">README for vagrant-lxc plugin</a></li>
<li> <a href="https://github.com/fgrehm/vagrant-lxc/wiki/Avoiding-%27sudo%27-passwords">vagrant-lxc &ndash; BUG &ndash; Avoiding &lsquo;sudo&rsquo; passwords</a></li>
<li> <a href="http://pfigue.github.io/blog/2014/01/25/my-first-steps-with-vagrant/">My first steps with Vagrant</a></li>
<li> <a href="http://fabiorehm.com/blog/2013/04/28/lxc-provider-for-vagrant/">LXC provider for Vagrant</a></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/01/25/my-first-steps-with-vagrant/">My first steps with Vagrant</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-01-25T12:52:00+01:00" pubdate data-updated="true">Jan 25<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>Why Vagrant?</h2>

<p>Lately I was developing my-own-solution &trade; for package deployment and now I&rsquo;d to check if I can install system packages without problems.</p>

<p><strong>Vagrant is a tool that lets me create, destroy and recreate Virtual Machines very easily</strong>, so I can in less than 5 minutes, create a new VM with a fresh install of Ubuntu 12.04 and install there the package I want to test.</p>

<p>It can also be useful to test system configuration (e.g. Puppet manifests or Chef recipes, nginx config., etc.) without playing with the production environment.</p>

<p>Another interesting use (and the reason I want to add Vagrant to the development toolchain my team uses at work) is to provide every developer with the option of packing his/her branch and deploy it with the help of Vagrant into a fresh VM, locally on his/her laptop.</p>

<p>Once deployed there, unit and functional test could be run in/against that VM, to be sure that every single branch sent to staging passed a minimal set of requirements.</p>

<h2>Replacing the old-Ubuntu-12.04 Vagrant install with a factory Vagrant.</h2>

<p>Long time ago I installed <strong>vagrant</strong> via <code>sudo apt-get install vagrant</code>, and since then I was getting an error whenever I tried to start a new project:</p>

<pre><code>$ vagrant init test1 http://cloud-images.ubuntu.com/vagrant/precise/current/precise-server-cloudimg-amd64-vagrant-disk1.box
/home/pablo/.rvm/rubies/ruby-2.0.0-p353/lib/ruby/site_ruby/2.0.0/rubygems/core_ext/kernel_require.rb:55:in `require': cannot load such file -- log4r (LoadError)
        from /home/pablo/.rvm/rubies/ruby-2.0.0-p353/lib/ruby/site_ruby/2.0.0/rubygems/core_ext/kernel_require.rb:55:in `require'
        from /usr/bin/vagrant:2:in `&lt;main&gt;'
</code></pre>

<p>I decided to remove the version of Vagrant shipped with Ubuntu 12.04, and install a new one from <a href="http://www.vagrantup.com/downloads.html">the debian package I could get via HashiCorp</a>:</p>

<pre><code>$ sudo apt-get remove --purge vagrant
$ wget "https://dl.bintray.com/mitchellh/vagrant/vagrant_1.4.3_x86_64.deb"
$ sudo dpkg -i vagrant_1.4.3_x86_64.deb
</code></pre>

<p>Due to the first installation of Vagrant, probably all the dependencies were already satisfied and I didn&rsquo;t have to install anything else.</p>

<h2>First project</h2>

<p>In Vagrant, you create a new directory for every project. In that directory will live a <code>Vagrantfile</code> with all the configuration of the VM(s) for that project.</p>

<pre><code>$ mkdir vagrant
$ cd vagrant/
$ vagrant init test1 http://cloud-images.ubuntu.com/vagrant/precise/current/precise-server-cloudimg-amd64-vagrant-disk1.box
A `Vagrantfile` has been placed in this directory. You are now
ready to `vagrant up` your first virtual environment! Please read
the comments in the Vagrantfile as well as documentation on
`vagrantup.com` for more information on using Vagrant.
</code></pre>

<p>If you are going to use Vagrant as a testing/deployment solution at work, you may find interesting to track the Vagrantfile via a <em>git</em> repository.</p>

<p>Let&rsquo;s edit the Vagrantfile a little bit to redirect the port 8080 on my laptop to the port 8000 in the test1 VM. The result would look like:</p>

<pre><code># Vagrantfile API/syntax version. Don't touch unless you know what you're doing!
VAGRANTFILE_API_VERSION = "2"

Vagrant.configure(VAGRANTFILE_API_VERSION) do |config|
  config.vm.box = "test1"
  config.vm.box_url = "http://cloud-images.ubuntu.com/vagrant/precise/current/precise-server-cloudimg-amd64-vagrant-disk1.box"
  config.vm.network :forwarded_port, guest: 8000, host: 8080
end
</code></pre>

<p>The URL <a href="http://cloud-images.ubuntu.com/vagrant/precise/current/precise-server-cloudimg-amd64-vagrant-disk1.box">http://cloud-images.ubuntu.com/vagrant/precise/current/precise-server-cloudimg-amd64-vagrant-disk1.box</a> is a boxed <a href="http://cloud-images.ubuntu.com/vagrant/precise/current/precise-server-cloudimg-amd64-vagrant-disk1.box">Ubuntu 12.04 amd64 (for VirtualBox)</a> that I found in <a href="http://www.vagantbox.es">vagrantbox.es</a>.</p>

<p>Once the file is edited and saved, if now I run <code>vagrant up</code>, as it is the first time I fire that VM up, it will fetch the .box file (around 400M big) and create the VM.</p>

<p>Per default, the virtualization <em>provider</em> is VirtualBox, but I&rsquo;ve seen boxes for VMWare and for Linux Containers (LXC).</p>

<h2>Testing the port redirect</h2>

<p>Typing <code>vagrant ssh</code> in the shell inside the <code>vagrant/</code> directory will establish an SSH session with the VM.</p>

<p>Once there you can type this to get netcat listening on port 8000 of the VM:</p>

<pre><code>$ nc -l 0.0.0.0 8000
</code></pre>

<p>In other terminal you can try to access the port 8080 of your computer (the host of the VM), like:</p>

<pre><code>$ curl http://127.0.0.1:8080
</code></pre>

<p>It should redirect the packets from 8080/tcp in the host to 8000/tcp in the VM, and you should be able to see the HTTP request in the terminal where netcat is running.</p>

<h2>Trying a network bridge instead of a port redirect</h2>

<p>If the VM will need to access a computer in the same network as the host (e.g. a database server), or the VM will be accessed by a computer different than the host (e.g. a <a href="http://code.google.com/p/selenium/wiki/Grid2">Selenium Grid</a>), you may find easier to install a network bridge better than redirect some ports.</p>

<p>With that purpose in mind, the Vagrantfile should be something like:</p>

<pre><code># Vagrantfile API/syntax version. Don't touch unless you know what you're doing!
VAGRANTFILE_API_VERSION = "2"

Vagrant.configure(VAGRANTFILE_API_VERSION) do |config|
  config.vm.box = "test1"
  config.vm.box_url = "http://cloud-images.ubuntu.com/vagrant/precise/current/precise-server-cloudimg-amd64-vagrant-disk1.box"
  config.vm.network :public_network
end
</code></pre>

<p>The new Vagrant configuration can be applied with <code>vagrant reload</code>. That command will stop (in a polite and slow way) and start again the VMs, asking this time the user in the command-line for which network interface will be the VM bridged to.</p>

<p>Once the VM is completelly booted, from a <code>vagrant ssh</code> session, the available interfaces can be checked:</p>

<pre><code>$ ifconfig -a | perl -ne 'print "$1\n" if m/^(\S+)/'
eth0
eth1
lo
$ ifconfig eth1 | grep inet\ addr
          inet addr:192.168.0.105  Bcast:192.168.0.255  Mask:255.255.255.0
</code></pre>

<p>So, my VM got the IP address 192.168.0.105. If I start a netcat in port 90/tcp with <code>sudo nc -l 0.0.0.0 90</code></p>

<p>Then, I should be able to connect to port 90/tcp of the VM from my laptop, with something like <code>telnet 192.168.0.105 90</code>.</p>

<p>Once you stop playing with Vagrant, you can stop the VM via <code>vagrant halt</code>.</p>

<p>References:</p>

<ul>
<li><p> <a href="http://www.jedi.be/blog/2011/03/28/using-vagrant-as-a-team/">Using Vagrant as a Team &ndash; Just Enough Developed Infrastructure</a></p></li>
<li><p> <a href="http://www.vagrantbox.es/">A list of base boxes for Vagrant</a></p></li>
<li><p> <a href="http://www.vagrantup.com/downloads.html">Vagrant Packages and Tarballs</a></p></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/12/06/configuring-dnsmasq-to-serve-my-own-domain-name-zone/">Configuring dnsmasq to serve my own domain name zone</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-12-06T17:07:00+01:00" pubdate data-updated="true">Dec 6<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>Why a name server and why dnsmasq.</h1>

<p>I have a datacenter (Acme GmbH.), with several environments (green, blue, live, staging), each environment with several servers (server1, server2, &hellip; serverX) and I want to use a domain name service to name every server on the datacenter, so every server can easily know what is the IP of server3.staging.acme, for example.</p>

<p>I may want also to create some aliases like puppet-master.acme.</p>

<p>While I could do this with BIND, it actually seems easier to me to user <em>dnsmasq</em>.</p>

<p>dnsmasq is a small DNS server easy to configure. It has also DHCP integration (and TFTP, PXE, etc.) but it is not what I am looking for.</p>

<p>As alternatives to use my own DNS server, I could choose some setup with Route 53 as user of Amazon. Digital Ocean or other providers may have their own systems.</p>

<h1>Installing</h1>

<p>In Ubuntu 12.04 it is just <code>sudo apt-get install dnsmasq</code>. It will launch the service, that you can stop via <code>/etc/init.d/dnsmasq stop</code>.</p>

<p>The configuration file is in <code>/etc/dnsmasq.conf</code>. The files in <code>/etc/dnsmasq.d/</code> can be included from dnsmasq.conf, but per default they aren&rsquo;t.</p>

<h1>Testing and finding the right configuration</h1>

<p>The <em>&mdash;no-daemon</em> option will be useful to do test in the command line:</p>

<pre><code>/usr/sbin/dnsmasq --no-daemon
</code></pre>

<p><em>&mdash;no-hosts</em> and <em>&mdash;addn-hosts=/etc/hosts.acme</em> will prevent dnsmasq to read /etc/hosts and instead load the datacenter zone configuration from <code>/etc/hosts.acme</code>:</p>

<pre><code>/usr/sbin/dnsmasq --no-daemon --no-hosts --addn-hosts=/etc/hosts.acme
</code></pre>

<p><em>&mdash;interface=eth0</em> will force dnsmasq to listen only on that interface. In my case, this will run in an AWS EC2 Instance, so I can configure in the Amazon Web Console the Security Groups to firewall the service and let only the legit servers to access the zone entries instead of everybody in the Amazon Datacenter network.</p>

<p><em>&mdash;no-resolv</em> will avoid dnsmasq to read the list of name servers from <code>/etc/resolv.conf</code> and <em>&mdash;server=&ldquo;8.8.4.4&rdquo;</em> will provide a default one, in this case a Google nameserver</p>

<pre><code>/usr/sbin/dnsmasq --no-daemon --no-hosts --addn-hosts=/etc/hosts.acme --interface=eth0 --no-resolv --server="8.8.4.4"
</code></pre>

<h1>Setting up the DNS server</h1>

<p>Instead of launching the command manually, we will launch the service via <code>/etc/init.d/dnsmasq start|status|stop</code>. The default configuration is <code>/etc/dnsmasq.conf</code> and I have this there:</p>

<pre><code>no-resolv
server=8.8.4.4
server=8.8.8.8
interface=eth0
no-dhcp-interface=eth0
no-hosts
addn-hosts=/etc/hosts.acme
log-queries
log-dhcp
</code></pre>

<p>The <strong>user</strong> and <strong>group</strong> directives are not needed in Ubuntu, as the server is run always ad <strong>dnsmasq</strong> user. Only during testing we will use <strong>log-queries</strong> and <strong>log-dhcp</strong>, to see what is going on. Once finished the tests, we can remove them.</p>

<p>In <code>/etc/hosts.acme</code> just 1 entry (if you are copying tis, be sure of using a valid IP address, with numbers, not that z.z.z.z):</p>

<pre><code>z.z.z.z     server2.staging.acme
</code></pre>

<p>If I launch the service like <code>/usr/sbin/dnsmasq -C /etc/dnsmasq.conf --no-daemon</code> (as root) I get this:</p>

<pre><code>dnsmasq: started, version 2.59 cachesize 150
dnsmasq: compile time options: IPv6 GNU-getopt DBus i18n DHCP TFTP conntrack IDN
dnsmasq: using nameserver 8.8.8.8#53
dnsmasq: using nameserver 8.8.4.4#53
dnsmasq: read /etc/hosts.acme - 1 addresses
</code></pre>

<p>Then, from other server (IP: y.y.y.y) with access to port 53/udp of the server (name: server1.acme, IP: x.x.x.x) where dnsmasq is running, I do:</p>

<pre><code># dig @server1.acme www.google.de

; &lt;&lt;&gt;&gt; DiG 9.8.1-P1 &lt;&lt;&gt;&gt; @server1.acme www.google.de
; (1 server found)
;; global options: +cmd
;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 43199
;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0

;; QUESTION SECTION:
;www.google.de.                 IN      A

;; ANSWER SECTION:
www.google.de.          300     IN      A       74.125.24.94

;; Query time: 21 msec
;; SERVER: x.x.x.x#53(x.x.x.x)
;; WHEN: Tue Dec  3 16:35:58 2013
;; MSG SIZE  rcvd: 47
</code></pre>

<p>It seems the name server can resolve external domain names. And actually I see in the server:</p>

<pre><code>dnsmasq: query[A] www.google.de from y.y.y.y
dnsmasq: forwarded www.google.de to 8.8.4.4
dnsmasq: forwarded www.google.de to 8.8.8.8
dnsmasq: reply www.google.de is 74.125.24.94
</code></pre>

<p>So, it seems to be forwarding my requests to google&rsquo;s DNSs (8.8.4.4 and 8.8.8.8) as they are not in the cache of dnsmasq.</p>

<p>If I ask again (2 seconds later) for the same external name:</p>

<pre><code>dig @server1.acme www.google.de

; &lt;&lt;&gt;&gt; DiG 9.8.1-P1 &lt;&lt;&gt;&gt; @server1.acme www.google.de
; (1 server found)
;; global options: +cmd
;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 36570
;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0

;; QUESTION SECTION:
;www.google.de.                 IN      A

;; ANSWER SECTION:
www.google.de.          298     IN      A       74.125.24.94

;; Query time: 2 msec
;; SERVER: x.x.x.x#53(x.x.x.x)
;; WHEN: Tue Dec  3 16:36:00 2013
;; MSG SIZE  rcvd: 47
</code></pre>

<p>The answer I get has a TTL 2 seconds lower and in the server I see:</p>

<pre><code>dnsmasq: query[A] www.google.de from y.y.y.y
dnsmasq: cached www.google.de is 74.125.24.94
</code></pre>

<p>This time dnsmasq had the answer itself and didn&rsquo;t need to forward. In fact the query time went from 21msec to 2msec.</p>

<p>If I ask for an internal name:</p>

<pre><code>dig @server1.acme server2.staging.acme

; &lt;&lt;&gt;&gt; DiG 9.8.1-P1 &lt;&lt;&gt;&gt; @server1.acme server2.staging.acme;
; (1 server found)
;; global options: +cmd
;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 54617
;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0

;; QUESTION SECTION:
;server2.staging.acme.           IN      A

;; ANSWER SECTION:
server2.staging.acme.    0       IN      A       z.z.z.z

;; Query time: 2 msec
;; SERVER: x.x.x.x#53(x.x.x.x)
;; WHEN: Tue Dec  3 16:36:13 2013
;; MSG SIZE  rcvd: 53
</code></pre>

<p>I get this in the server:</p>

<pre><code>dnsmasq: query[A] server2.staging.acme from y.y.y.y
dnsmasq: /etc/hosts.acme server2.staging.acme is z.z.z.z
</code></pre>

<p>The server is also able to solve internal names.</p>

<h1>Automatising the installation with Puppet</h1>

<p>I have a <a href="https://gist.github.com/pfigue/7772289">Gist with an draft of a manifest</a> for Puppet.</p>

<p>Use <code>puppet apply --noop dnsmasq.pp</code> to check it (eventually w/o &mdash;noop).</p>

<h1>References:</h1>

<ul>
<li><a href="http://www.thekelleys.org.uk/dnsmasq/docs/dnsmasq-man.html">dnsmasq manual page</a></li>
<li><a href="http://en.wikipedia.org/wiki/Comparison_of_DNS_server_software">Comparison of DNS Server Software</a></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/12/04/replacing-dhcp-automatic-name-resolution-config-with-my-own-static-one/">Replacing DHCP automatic name resolution config with my own static one</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-12-04T13:07:00+01:00" pubdate data-updated="true">Dec 4<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><em>Problem1:</em> I have an AWS EC2 Instance (Ubuntu 12.04) where I want to use <a href="http://pfigue.github.io/blog/2013/12/06/configuring-dnsmasq-to-serve-my-own-domain-name-zone/">my own DNS service</a>, not the default one provided by Amazon.</p>

<p><em>Solution1:</em> Definining a static DNS server configuration</p>

<p>In <code>/etc/network/interfaces</code> you can specify <strong>dns-search</strong> and <strong>dns-nameservers</strong> in the configuration of the network interface,</p>

<pre><code># The primary network interface
auto eth0
iface eth0 inet dhcp
        dns-search acme
        dns-nameservers 1.2.3.4
</code></pre>

<p>Now if you apply this configuration with <code>/etc/init.d/networking restart</code>, you will be able to see changes in <code>/etc/resolv.conf</code>.</p>

<p><em>Note1:</em> Restarting the network services didn&rsquo;t disconnect me from the computer I was configuring.</p>

<p><em>Note2:</em> There may be better ways to apply changes in the network config.</p>

<p><em>Problem2:</em> In /etc/resolv.conf there is my static configuration <strong>together with the DNS setup received via DHCP</strong>, and I want only my configuration without the one provided by DHCP.</p>

<p><em>Solution2:</em> Avoid the DNS setup from DHCP.</p>

<p>My system is using dhclient3, and the config. file for it is in <code>/etc/dhcp/dhclient.conf</code>. There, I comment the options to retrieve the DNS config from the DHCP service:</p>

<pre><code>request subnet-mask, broadcast-address, time-offset, routers,
        #domain-name, domain-name-servers, domain-search, host-name,
        netbios-name-servers, netbios-scope, interface-mtu,
        rfc3442-classless-static-routes, ntp-servers,
</code></pre>

<p>Now if I restart the <code>networking</code> service again, <code>/etc/resolv.conf</code> will have the right domain and nameservers.</p>

<p>References:</p>

<ul>
<li><a href="http://ubuntuforums.org/showthread.php?t=1320773">Static DNS with DHCP</a></li>
<li><a href="https://help.ubuntu.com/12.04/serverguide/network-configuration.html#name-resolution">Ubuntu 12.04: Network Configuration: Name Resolution</a></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/11/29/a-puppet-manifest-to-set-the-timezone/">A Puppet Manifest to set the timezone</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-11-29T16:48:00+01:00" pubdate data-updated="true">Nov 29<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I am getting to know Puppet and right now I would like to set the timezone of my servers in an automated way via Puppet Manifests.</p>

<h1>Ensuring the presence and content of a file</h1>

<p>I created a new file <code>timezone.pp</code> and wrote inside:</p>

<pre><code>file { '/etc/timezone':
    ensure =&gt; present,
    content =&gt; "Europe/Berlin\n",
}
</code></pre>

<p>Saved it, and run <code>puppet apply --noop timezone.pp</code> as root. The <em>&mdash;noop</em> is to indicate puppet that I want a dry-run, to not make any changes into the system, just validate the Manifest.</p>

<p>Those 4 lines define a <a href="http://docs.puppetlabs.com/references/latest/type.html#file">ressource type file</a>, the name of the ressource and (in this case) also the path of the file is <em>/etc/timezone</em>, the file should be present into the filesystem and the content should be the indicated one.</p>

<p>With the file ressource I could also define symbolic links, directories, etc.</p>

<p>Once the validation with <code>puppet apply --noop</code> was okay, I moved to the next step.</p>

<h1>Running an external command</h1>

<p>With the <em>exec</em> ressource I can run a command as a given user. The command should be expressed as an absolute path, so <code>/usr/sbin/dpkg-reconfigure</code> instead of <code>dpkg-reconfigure</code>:</p>

<pre><code>exec { 'reconfigure-tzdata':
        user =&gt; root,
        group =&gt; root,
        command =&gt; '/usr/sbin/dpkg-reconfigure --frontend noninteractive tzdata',
}
</code></pre>

<p>Also note that the <a href="https://help.ubuntu.com/community/UbuntuTime#Using_the_Command_Line_.28unattended.29">command won&rsquo;t require input from the user</a> and it will be run as root.</p>

<h1>Reporting and being talkative</h1>

<p>To keep the user updated and make the debugging easier, I would like to notify the user what is going on:</p>

<pre><code>notify { 'timezone-changed':
        message =&gt; 'Timezone was updated to Europe/Berlin',
}
</code></pre>

<p>This ressource will be named <code>timezone-changed</code> and represents a notification message. There are also fail{} and notice{} ressources, afaik.</p>

<h1>Execution order</h1>

<p>Puppet Manifests are declarative. You just write down statement of what do you want to get, not how to get it.</p>

<p>Now I want to express that the <em>timezone-changed notify ressource</em> should be executed only after the <em>reconfigure-tzdata exec ressource</em>. And this one should be executed only after <em>/etc/timezone file ressource</em>:</p>

<pre><code>File['/etc/timezone'] -&gt; Exec['reconfigure-tzdata'] -&gt; Notify['timezone-changed']
</code></pre>

<p>So, if /etc/timezone already exists and has the right contents and (in general) meets the specification of the ressource we wrote in the manifest, no reconfigure-tzdata will be executed and no notification will happen.</p>

<h1>Applying the changes</h1>

<p>Having all the previous ressources and ordering in <a href="https://gist.github.com/pfigue/7694021">timezone.pp</a>, as root I run <code>puppet apply timezone.pp</code>:</p>

<pre><code>notice: /Stage[main]//File[/etc/timezone]/content: content changed '{md5}4f24b133ba38d8fd565168742c9aedeb' to '{md5}749357f70f40574f632071ec7d5f41a9'
notice: /Stage[main]//Exec[reconfigure-tzdata]/returns: executed successfully
notice: Timezone was updated to Europe/Berlin
notice: /Stage[main]//Notify[timezone-changed]/message: defined 'message' as 'Timezone was updated to Europe/Berlin'
notice: Finished catalog run in 1.16 seconds
</code></pre>

<p>Checking:</p>

<pre><code># date
Thu Nov 28 16:10:51 CET 2013
#
</code></pre>

<p>Time zone is now <em>CET</em> which is Berlin, which is right.</p>

<h1>References:</h1>

<ul>
<li><a href="https://help.ubuntu.com/community/UbuntuTime#Using_the_Command_Line_.28unattended.29">Unattended timezone change in Ubuntu</a></li>
<li><a href="http://docs.puppetlabs.com/references/latest/type.html">List of Ressources for Puppet</a></li>
<li><a href="http://docs.puppetlabs.com/learning/ordering.html">Ressource Ordering in Puppet</a></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/11/28/a-custom-facter-fact-to-read-aws-user-data/">A custom Facter fact to read AWS User-Data</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-11-28T12:35:00+01:00" pubdate data-updated="true">Nov 28<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>I need to do the provisioning of some AWS EC2 Instances depending on their role.</h2>

<p>Some of them will need to install some packages with some configuration, others will need different packages and different configuration, depending on the role they will adopt in the new system.</p>

<p>For this reason I need Puppet to behave in a different way depending on a <strong>fact</strong>, the <em>server flavour</em> of the server who is being provisioned.</p>

<h2>How to communicate the role to Puppet</h2>

<p>The first exercise would be to learn how <a href="http://pfigue.github.io/blog/2013/11/27/how-to-add-custom-facts-to-facter/">to write a new dummy fact for Facter</a>, so we are sure we can write facts for Puppet.</p>

<p>The second goal would be to write a new fact that actually reads the role of the server.</p>

<h3>Appending custom information to an EC2 instance.</h3>

<p>I communicate the role (and other information) to a new server <strong>via User-Data</strong>, whenever I <em>Launch a New Instance</em> from the AWS Web Console.
During the 3rd step, named <em>Configure Instance Details</em>, I have the option to define <em>Advanced Details</em>, one of them the <em>User data</em>.</p>

<p>Once the instance is running, I <strong>can&rsquo;t change that User-Data</strong>. If I want to, I need to destroy that instance and create a new one with the new data.</p>

<p>An <strong>alternative to User-Data is to use <em>Tags</em></strong>, and then the EC2 Command-Line Tools to access and read information from those Tags. But you should mind that there is a <strong>limit of 10 tags per server</strong>, so it may not be the best solution. On the other hand, <strong>you can change the tags while the Instance is running</strong>. No need to destroy it.</p>

<p>I upload a YAML file with all the information, and then, once the new EC2 Instance is up, from the instance itself I can get that YAML file:</p>

<pre><code>$ /usr/bin/curl --silent "http://169.254.169.254/latest/user-data/"
instance:
    flavor: application-server
$
</code></pre>

<p>With <a href="https://gist.github.com/pfigue/7690424">some python scripting like</a>:</p>

<pre><code>import sys
import yaml

if __name__ == '__main__':
    contents = sys.stdin.read()
    document = yaml.load(contents)
    for key in sys.argv[1:]:
            try:
                    document = document[key]
            except KeyError:
                    sys.exit(1)
    sys.stdout.write(str(document))
    sys.stdout.flush()
    sys.exit(0)
</code></pre>

<p>I can provide the script the YAML via stdin and then ask for some data:</p>

<pre><code>$ curl --silent "http://169.254.169.254/latest/user-data/" | python ./ec2-user-data-parser.py instance flavor
application-server
$
</code></pre>

<h3>Writting the Facter <em>fact</em></h3>

<p>Writting a new fact is now straight forward (I saved the python script in <code>/root/tools/ec2-user-data-parser.py</code>):</p>

<pre><code># server_flavor.rb

Facter.add("server_flavor") do
  setcode do
    Facter::Util::Resolution.exec('/usr/bin/curl --silent "http://169.254.169.254/latest/user-data/" | /usr/bin/python /root/tools/ec2-user-data-parser.py instance flavor')
  end
end
</code></pre>

<p>I save the code to <code>/root/facter/server_flavor.rb</code> and then test it:</p>

<pre><code>$ FACTERLIB=/root/facter/ facter server_flavor
application-server
$
</code></pre>

<p>I may need still to add some <code>export FACTERLIB=/root/facter/</code> to <code>/root/.bashrc</code>, but now my puppet manifests will know which kind of Amazon servers they are provisioning.</p>

<h2>References:</h2>

<ul>
<li><a href="https://gist.github.com/pfigue/7690424">The code in a Gist</a></li>
<li><a href="http://docs.puppetlabs.com/guides/custom_facts.html">Puppet Docs: Custom Facts</a></li>
<li><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AESDG-chapter-instancedata.html">AWS Instance Meta- and User- Data</a></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/11/27/how-to-add-custom-facts-to-facter/">How to add custom facts to Facter</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-11-27T18:55:00+01:00" pubdate data-updated="true">Nov 27<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>What is Facter?</h2>

<p>It is a Ruby tool that informs you about facts.</p>

<p>As far as I know, it is used often from Puppet, to know about properties of the environment you are going to provision.</p>

<p>Those properties can be things like <em>Operating System</em>, <em>Version of the kernel</em>, <em>Architecture</em>, <em>Amazon EC2 Instance ID</em>, <em>Available memory</em>, <em>Number of processors</em>, etc.</p>

<p>The <code>facter</code> tool by default has some values like those above: you can run <code>facter</code> in the shell to get a list of <em>facts</em>.</p>

<p>From a Puppet Manifest you could write statements dependent on those facts.
For example, to install some package when the manifest is applied to a Debian system, and install a different package when applied to a Red Hat one.</p>

<h2>Do you need to define your own Facts?</h2>

<p><strong>Facter</strong> looks for the <em>FACTERLIB</em> environment variable, which may point to a directory, if it is defined.</p>

<p>If you put in that directory a file named <code>hardware_platform.rb</code> (note the <em>.rb</em> extension), and inside you define:</p>

<pre><code># hardware_platform.rb

Facter.add("hardware_platform") do
    setcode do
        Facter::Util::Resolution.exec('/bin/uname -i')
    end
end
</code></pre>

<p>There will appear a new <em>Fact</em> called <em>hardware_platform</em>:</p>

<pre><code># facter | grep -i platform
hardware_platform =&gt; x86_64
#
</code></pre>

<p>You can invoke it also via <code>facter hardware_platform</code>:</p>

<pre><code># facter hardware_platform
x86_64
#
</code></pre>

<p>Pay attention, that the file name and the Fact name are the same. An the file extension is <em>.rb</em>.</p>

<p>In this way, you can have your own facts for your Puppet manifests.</p>

<p>Puppet Docs has much <a href="http://docs.puppetlabs.com/guides/custom_facts.html">more information</a>.</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <ul id="recent_posts">
      <li class="post">
      <a href="http://pfigue.github.com" alt="Home"><img src="/images/Home.png"></a>
      <a href="http://pfigue.github.com/archives/" alt="Archives"><img src="/images/Calendar.png"></a>
      <a href="mailto:" alt="E-Mail"><img src="/images/Envelope.png"></a>
      <a href="http://pfigue.github.com/atom.xml" alt="subscribe feed"><img src="/images/rss_big.png"></a>
      </li>
  </ul>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2015/03/06/file-descriptors-and-elasticsearch/">File Descriptors and ElasticSearch</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/04/02/bulk-user-creation-in-vbulletin-5-with-casperjs/">Bulk user creation in vBulletin 5 with CasperJS</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/02/04/creating-a-new-profile-for-lintian/">Creating a new profile for Lintian</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/01/25/using-vagrant-with-lxc-linux-containers/">Using Vagrant with LXC Linux Containers</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/01/25/my-first-steps-with-vagrant/">My first steps with Vagrant</a>
      </li>
    
  </ul>
</section>


<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("__pfigue", 4, false);
    });
  </script>
  <script src="/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/__pfigue" class="twitter-follow-button" data-show-count="false">Follow @__pfigue</a>
  
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - pfigue -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'pfigue';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>





  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
